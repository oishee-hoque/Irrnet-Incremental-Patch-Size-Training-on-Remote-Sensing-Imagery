{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e34719b3-df51-42d7-a2a1-bfd4ec7fc289",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n",
      "Estimated parameters TOTSAMPLE=20829,TRAIN_SIZE=3929,EVAL_SIZE=876, BUFFER_SIZE=8370\n",
      "/scratch/gza5dr/IrrigationTypeDetection/Experinments/All_NEW/Irrigation_detection/Irrigation_detection_WRLU_NoCDL_Balanced_Normalized_Unique_UT_lib7_3_new/Samples_2003_256x256_g_train.tfrecord.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-15 02:55:07.619224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1636] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78791 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:0f:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 40 elements to TFRecord\n",
      "/scratch/gza5dr/IrrigationTypeDetection/Experinments/All_NEW/Irrigation_detection/Irrigation_detection_WRLU_NoCDL_Balanced_Normalized_Unique_UT_lib7_3_new/Samples_2004_256x256_g_train.tfrecord.gz\n",
      "Wrote 31 elements to TFRecord\n",
      "/scratch/gza5dr/IrrigationTypeDetection/Experinments/All_NEW/Irrigation_detection/Irrigation_detection_WRLU_NoCDL_Balanced_Normalized_Unique_UT_lib7_3_new/Samples_2005_256x256_g_train.tfrecord.gz\n",
      "Wrote 7 elements to TFRecord\n",
      "/scratch/gza5dr/IrrigationTypeDetection/Experinments/All_NEW/Irrigation_detection/Irrigation_detection_WRLU_NoCDL_Balanced_Normalized_Unique_UT_lib7_3_new/Samples_2006_256x256_g_train.tfrecord.gz\n",
      "Wrote 19 elements to TFRecord\n",
      "/scratch/gza5dr/IrrigationTypeDetection/Experinments/All_NEW/Irrigation_detection/Irrigation_detection_WRLU_NoCDL_Balanced_Normalized_Unique_UT_lib7_3_new/Samples_2007_256x256_g_train.tfrecord.gz\n",
      "Wrote 14 elements to TFRecord\n",
      "/scratch/gza5dr/IrrigationTypeDetection/Experinments/All_NEW/Irrigation_detection/Irrigation_detection_WRLU_NoCDL_Balanced_Normalized_Unique_UT_lib7_3_new/Samples_2008_256x256_g_train.tfrecord.gz\n",
      "Wrote 10 elements to TFRecord\n",
      "/scratch/gza5dr/IrrigationTypeDetection/Experinments/All_NEW/Irrigation_detection/Irrigation_detection_WRLU_NoCDL_Balanced_Normalized_Unique_UT_lib7_3_new/Samples_2009_256x256_g_train.tfrecord.gz\n",
      "Wrote 33 elements to TFRecord\n",
      "/scratch/gza5dr/IrrigationTypeDetection/Experinments/All_NEW/Irrigation_detection/Irrigation_detection_WRLU_NoCDL_Balanced_Normalized_Unique_UT_lib7_3_new/Samples_2010_256x256_g_train.tfrecord.gz\n",
      "Wrote 29 elements to TFRecord\n",
      "/scratch/gza5dr/IrrigationTypeDetection/Experinments/All_NEW/Irrigation_detection/Irrigation_detection_WRLU_NoCDL_Balanced_Normalized_Unique_UT_lib7_3_new/Samples_2011_256x256_g_train.tfrecord.gz\n",
      "Wrote 3 elements to TFRecord\n",
      "/scratch/gza5dr/IrrigationTypeDetection/Experinments/All_NEW/Irrigation_detection/Irrigation_detection_WRLU_NoCDL_Balanced_Normalized_Unique_UT_lib7_3_new/Samples_2013_256x256_g_train.tfrecord.gz\n",
      "Wrote 7 elements to TFRecord\n",
      "/scratch/gza5dr/IrrigationTypeDetection/Experinments/All_NEW/Irrigation_detection/Irrigation_detection_WRLU_NoCDL_Balanced_Normalized_Unique_UT_lib7_3_new/Samples_2014_256x256_g_train.tfrecord.gz\n",
      "Wrote 9 elements to TFRecord\n",
      "/scratch/gza5dr/IrrigationTypeDetection/Experinments/All_NEW/Irrigation_detection/Irrigation_detection_WRLU_NoCDL_Balanced_Normalized_Unique_UT_lib7_3_new/Samples_2015_256x256_g_train.tfrecord.gz\n",
      "Wrote 37 elements to TFRecord\n",
      "/scratch/gza5dr/IrrigationTypeDetection/Experinments/All_NEW/Irrigation_detection/Irrigation_detection_WRLU_NoCDL_Balanced_Normalized_Unique_UT_lib7_3_new/Samples_2018_256x256_g_train.tfrecord.gz\n",
      "Wrote 112 elements to TFRecord\n",
      "/scratch/gza5dr/IrrigationTypeDetection/Experinments/All_NEW/Irrigation_detection/Irrigation_detection_WRLU_NoCDL_Balanced_Normalized_Unique_UT_lib7_3_new/Samples_2019_256x256_g_train.tfrecord.gz\n",
      "Wrote 115 elements to TFRecord\n",
      "/scratch/gza5dr/IrrigationTypeDetection/Experinments/All_NEW/Irrigation_detection/Irrigation_detection_WRLU_NoCDL_Balanced_Normalized_Unique_UT_lib7_3_new/Samples_2020_256x256_g_train.tfrecord.gz\n",
      "Wrote 116 elements to TFRecord\n",
      "/scratch/gza5dr/IrrigationTypeDetection/Experinments/All_NEW/Irrigation_detection/Irrigation_detection_WRLU_NoCDL_Balanced_Normalized_Unique_UT_lib7_3_new/Samples_2021_256x256_g_train.tfrecord.gz\n",
      "Wrote 116 elements to TFRecord\n",
      "/scratch/gza5dr/IrrigationTypeDetection/Experinments/All_NEW/Irrigation_detection/Irrigation_detection_WRLU_NoCDL_Balanced_Normalized_Unique_UT_lib7_3_new/Samples_2003_256x256_g_eval.tfrecord.gz\n",
      "Wrote 11 elements to TFRecord\n",
      "/scratch/gza5dr/IrrigationTypeDetection/Experinments/All_NEW/Irrigation_detection/Irrigation_detection_WRLU_NoCDL_Balanced_Normalized_Unique_UT_lib7_3_new/Samples_2004_256x256_g_eval.tfrecord.gz\n",
      "Wrote 4 elements to TFRecord\n",
      "/scratch/gza5dr/IrrigationTypeDetection/Experinments/All_NEW/Irrigation_detection/Irrigation_detection_WRLU_NoCDL_Balanced_Normalized_Unique_UT_lib7_3_new/Samples_2005_256x256_g_eval.tfrecord.gz\n",
      "Wrote 2 elements to TFRecord\n",
      "/scratch/gza5dr/IrrigationTypeDetection/Experinments/All_NEW/Irrigation_detection/Irrigation_detection_WRLU_NoCDL_Balanced_Normalized_Unique_UT_lib7_3_new/Samples_2006_256x256_g_eval.tfrecord.gz\n",
      "Wrote 9 elements to TFRecord\n",
      "/scratch/gza5dr/IrrigationTypeDetection/Experinments/All_NEW/Irrigation_detection/Irrigation_detection_WRLU_NoCDL_Balanced_Normalized_Unique_UT_lib7_3_new/Samples_2007_256x256_g_eval.tfrecord.gz\n",
      "Wrote 4 elements to TFRecord\n",
      "/scratch/gza5dr/IrrigationTypeDetection/Experinments/All_NEW/Irrigation_detection/Irrigation_detection_WRLU_NoCDL_Balanced_Normalized_Unique_UT_lib7_3_new/Samples_2008_256x256_g_eval.tfrecord.gz\n",
      "Wrote 5 elements to TFRecord\n",
      "/scratch/gza5dr/IrrigationTypeDetection/Experinments/All_NEW/Irrigation_detection/Irrigation_detection_WRLU_NoCDL_Balanced_Normalized_Unique_UT_lib7_3_new/Samples_2009_256x256_g_eval.tfrecord.gz\n",
      "Wrote 7 elements to TFRecord\n",
      "/scratch/gza5dr/IrrigationTypeDetection/Experinments/All_NEW/Irrigation_detection/Irrigation_detection_WRLU_NoCDL_Balanced_Normalized_Unique_UT_lib7_3_new/Samples_2010_256x256_g_eval.tfrecord.gz\n",
      "Wrote 4 elements to TFRecord\n",
      "/scratch/gza5dr/IrrigationTypeDetection/Experinments/All_NEW/Irrigation_detection/Irrigation_detection_WRLU_NoCDL_Balanced_Normalized_Unique_UT_lib7_3_new/Samples_2011_256x256_g_eval.tfrecord.gz\n",
      "Wrote 3 elements to TFRecord\n",
      "/scratch/gza5dr/IrrigationTypeDetection/Experinments/All_NEW/Irrigation_detection/Irrigation_detection_WRLU_NoCDL_Balanced_Normalized_Unique_UT_lib7_3_new/Samples_2013_256x256_g_eval.tfrecord.gz\n",
      "Wrote 2 elements to TFRecord\n",
      "/scratch/gza5dr/IrrigationTypeDetection/Experinments/All_NEW/Irrigation_detection/Irrigation_detection_WRLU_NoCDL_Balanced_Normalized_Unique_UT_lib7_3_new/Samples_2014_256x256_g_eval.tfrecord.gz\n",
      "Wrote 4 elements to TFRecord\n",
      "/scratch/gza5dr/IrrigationTypeDetection/Experinments/All_NEW/Irrigation_detection/Irrigation_detection_WRLU_NoCDL_Balanced_Normalized_Unique_UT_lib7_3_new/Samples_2015_256x256_g_eval.tfrecord.gz\n",
      "Wrote 8 elements to TFRecord\n",
      "/scratch/gza5dr/IrrigationTypeDetection/Experinments/All_NEW/Irrigation_detection/Irrigation_detection_WRLU_NoCDL_Balanced_Normalized_Unique_UT_lib7_3_new/Samples_2018_256x256_g_eval.tfrecord.gz\n",
      "Wrote 41 elements to TFRecord\n",
      "/scratch/gza5dr/IrrigationTypeDetection/Experinments/All_NEW/Irrigation_detection/Irrigation_detection_WRLU_NoCDL_Balanced_Normalized_Unique_UT_lib7_3_new/Samples_2019_256x256_g_eval.tfrecord.gz\n",
      "Wrote 41 elements to TFRecord\n",
      "/scratch/gza5dr/IrrigationTypeDetection/Experinments/All_NEW/Irrigation_detection/Irrigation_detection_WRLU_NoCDL_Balanced_Normalized_Unique_UT_lib7_3_new/Samples_2020_256x256_g_eval.tfrecord.gz\n",
      "Wrote 41 elements to TFRecord\n",
      "/scratch/gza5dr/IrrigationTypeDetection/Experinments/All_NEW/Irrigation_detection/Irrigation_detection_WRLU_NoCDL_Balanced_Normalized_Unique_UT_lib7_3_new/Samples_2021_256x256_g_eval.tfrecord.gz\n",
      "Wrote 41 elements to TFRecord\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "# In[34]:\n",
    "\n",
    "\n",
    "\n",
    "# Sizes of the training and evaluation datasets.\n",
    "#TRAIN_SIZE = 1703 #Use when non-ag included (does not include slope)\n",
    "## Approximate total number of 32x32 areas extracted:\n",
    "TOTSAMPLE = 3*(1539+1539+1569+261+114+49+105+486+177+147+203+275+282+197) #New balanced dataset is 3times as large as original \n",
    "                                                                          #N squares = number of fields /30 instead of /100\n",
    "## 80% of that is training\n",
    "\n",
    "\n",
    "#TRAIN_SIZE = int(TOTSAMPLE*0.8)\n",
    "#TRAIN_SIZE = 16231\n",
    "#TRAIN_SIZE = 3280 #Unique\n",
    "#TRAIN_SIZE = 633 #Unique AOC\n",
    "#TRAIN_SIZE = 894 #Unique AOC2\n",
    "#TRAIN_SIZE = 682 #Unique AOC3\n",
    "#TRAIN_SIZE = 1718 #Unique UT_l8_1\n",
    "#TRAIN_SIZE = 2277 #Unique UT_l8_8_29_22\n",
    "TRAIN_SIZE = 3929 #Unique UT_l8\n",
    "#EVAL_SIZE = 395 #Use when non-ag included (does not include slope)\n",
    "#EVAL_SIZE = TOTSAMPLE - TRAIN_SIZE\n",
    "#EVAL_SIZE = 4100\n",
    "#EVAL_SIZE = 824\n",
    "#EVAL_SIZE = 144 #Unique AOC\n",
    "#EVAL_SIZE = 246 #Unique AOC2\n",
    "#EVAL_SIZE = 187 #Unique AOC3\n",
    "#EVAL_SIZE = 383 #Unique UT_l8_1\n",
    "#EVAL_SIZE = 242 #Unique UT_l8_2\n",
    "#EVAL_SIZE = 498 #Unique UT_l8_8_29_22\n",
    "EVAL_SIZE = 876 #Unique UT_l8\n",
    "\n",
    "# Specify model training parameters.\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 1000 #Should auto-stop\n",
    "BUFFER_SIZE = 2*(TRAIN_SIZE+BATCH_SIZE)\n",
    "print(f'Estimated parameters TOTSAMPLE={TOTSAMPLE},TRAIN_SIZE={TRAIN_SIZE},EVAL_SIZE={EVAL_SIZE}, BUFFER_SIZE={BUFFER_SIZE}')\n",
    "\n",
    "\n",
    "YEARS_PYTHON = ['2005', '2016']\n",
    "FOLIUMLOCATION = [39.811,-111.625,]\n",
    "\n",
    "\n",
    "ALL_BANDS = ['0_BGR0_median', '0_BGR1_median', '0_BGR2_median', '0_SWIR0_median', '0_SWIR1_median', '0_SWIR2_median', '0_SR_TH_median', \n",
    "             '0_BGR0_diff', '0_BGR1_diff', '0_BGR2_diff', '0_SWIR0_diff', '0_SWIR1_diff', '0_SWIR2_diff', '0_SR_TH_diff', '1_BGR0_median', \n",
    "             '1_BGR1_median', '1_BGR2_median', '1_SWIR0_median', '1_SWIR1_median', '1_SWIR2_median', '1_SR_TH_median', '1_BGR0_diff', \n",
    "             '1_BGR1_diff', '1_BGR2_diff', '1_SWIR0_diff', '1_SWIR1_diff', '1_SWIR2_diff', '1_SR_TH_diff', '2_BGR0_median', '2_BGR1_median', \n",
    "             '2_BGR2_median', '2_SWIR0_median', '2_SWIR1_median', '2_SWIR2_median', '2_SR_TH_median', '2_BGR0_diff', '2_BGR1_diff', '2_BGR2_diff', \n",
    "             '2_SWIR0_diff', '2_SWIR1_diff', '2_SWIR2_diff', '2_SR_TH_diff', '3_BGR0_median', '3_BGR1_median', '3_BGR2_median', '3_SWIR0_median', \n",
    "             '3_SWIR1_median', '3_SWIR2_median', '3_SR_TH_median', '3_BGR0_diff', '3_BGR1_diff', '3_BGR2_diff', '3_SWIR0_diff', '3_SWIR1_diff', \n",
    "             '3_SWIR2_diff', '3_SR_TH_diff', 'BGR0_stdDev', 'BGR1_stdDev', 'BGR2_stdDev', 'SWIR0_stdDev', 'SWIR1_stdDev', 'SWIR2_stdDev', 'SR_TH_stdDev']\n",
    "\n",
    "\n",
    "\n",
    "SAVED_BANDS = [f'BGR{i}_median' for i in range(3)]+[f'SWIR{i}_median' for i in range(3)]+[f'SR_TH_median']+\\\n",
    "                [f'BGR{i}_diff' for i in range(3)]+[f'SWIR{i}_diff' for i in range(3)]+[f'SR_TH_diff']+\\\n",
    "                [f'BGR{i}_stdDev' for i in range(3)]+[f'SWIR{i}_stdDev' for i in range(3)]+[f'SR_TH_stdDev']\n",
    "\n",
    "RESPONSE = ['flood', 'sprinkler', 'other'] \n",
    "\n",
    "ALL_FEATURES = ALL_BANDS+RESPONSE\n",
    "\n",
    "\n",
    "\n",
    "# Specify the size and shape of patches expected by the model.\n",
    "KERNEL_SIZE = 256\n",
    "KERNEL_SHAPE = [KERNEL_SIZE, KERNEL_SIZE]\n",
    "COLUMNS = [\n",
    "  tf.io.FixedLenFeature(shape=KERNEL_SHAPE, dtype=tf.float32) for k in ALL_FEATURES\n",
    "]\n",
    "COLUMNS2 = [\n",
    "  tf.io.FixedLenFeature([], tf.string) for k in ALL_FEATURES\n",
    "]\n",
    "ALL_FEATURES_DICT = dict(zip(ALL_FEATURES, COLUMNS))\n",
    "ALL_FEATURES_DICT_STRING = dict(zip(ALL_FEATURES, COLUMNS2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Specify names locations for outputs in Cloud Storage. \n",
    "BASEFOLDER = '/scratch/gza5dr/IrrigationTypeDetection/Experinments/All_NEW/Irrigation_detection/Irrigation_detection_WRLU_NoCDL_Balanced_Normalized_Unique_UT_lib7_3_new'\n",
    "TRAINING_BASE = f'{KERNEL_SIZE}x{KERNEL_SIZE}_g_train'\n",
    "EVAL_BASE = f'{KERNEL_SIZE}x{KERNEL_SIZE}_g_eval'\n",
    "\n",
    "\n",
    "\n",
    "# # Training data\n",
    "# \n",
    "# Load the data exported from Earth Engine into a `tf.data.Dataset`.  The following are helper functions for that.\n",
    "\n",
    "# In[35]:\n",
    "\n",
    "import sys\n",
    "from keras import layers\n",
    "\n",
    "def parse_tfrecord(example_proto):\n",
    "  \"\"\"The parsing function.\n",
    "  Read a serialized example into the structure defined by FEATURES_DICT.\n",
    "  Args:\n",
    "    example_proto: a serialized Example.\n",
    "  Returns:\n",
    "    A dictionary of tensors, keyed by feature name.\n",
    "  \"\"\"\n",
    "  return tf.io.parse_single_example(example_proto, ALL_FEATURES_DICT)\n",
    "\n",
    "def to_tuple(inputs):\n",
    "  \"\"\"Function to convert a dictionary of tensors to a tuple of (inputs, outputs).\n",
    "  Turn the tensors returned by parse_tfrecord into a stack in HWC shape.\n",
    "  Args:\n",
    "    inputs: A dictionary of tensors, keyed by feature name.\n",
    "  Returns:\n",
    "    A tuple of (inputs, outputs).\n",
    "  \"\"\"\n",
    "  inputsList = [inputs.get(key) for key in ALL_FEATURES]\n",
    "  \n",
    "  stacked = tf.stack(inputsList, axis=0)\n",
    "  # Convert from CHW to HWC\n",
    "  stacked = tf.transpose(stacked, [1, 2, 0])\n",
    "  return stacked\n",
    "\n",
    "def sample_to_dict(inputs):\n",
    "    \"\"\"Function to convert a dictionary of tensors to a tuple of (inputs, outputs).\n",
    "    Turn the tensors returned by parse_tfrecord into a stack in HWC shape.\n",
    "    Args:\n",
    "    inputs: A dictionary of tensors, keyed by feature name.\n",
    "    Returns:\n",
    "    A tuple of (inputs, outputs).\n",
    "    \"\"\"\n",
    "    inputsList = {key:inputs.get(key) for key in ALL_FEATURES}\n",
    "    return inputsList\n",
    "\n",
    "\n",
    "def normalize_input(sample_dict):\n",
    "    '''This augments the data by applying random filps \n",
    "    and adding random noise\n",
    "    '''\n",
    "    for key in ALL_FEATURES:\n",
    "        if not (key in RESPONSE):\n",
    "            if True:\n",
    "                mean_ = tf.math.reduce_mean(sample_dict[key])\n",
    "                std_ = tf.math.reduce_std(sample_dict[key])\n",
    "                std_ = tf.math.add(std_, 1e-5)\n",
    "                centered = tf.math.subtract(sample_dict[key], mean_)\n",
    "                normalized_ = tf.math.divide(centered, std_)\n",
    "                normalized_ = tf.math.divide(normalized_, 3.0)\n",
    "                sample_dict[key] = normalized_\n",
    "            else:\n",
    "                sample_dict[key] = tf.math.divide(sample_dict[key], 65536)\n",
    "    return sample_dict\n",
    "\n",
    "def save_average_input(sample_dict):\n",
    "    '''This augments the data by applying random filps \n",
    "    and adding random noise\n",
    "    '''\n",
    "    to_drop = []\n",
    "    sample_dict_out = {}\n",
    "    for band_ in ['BGR', 'SWIR']:\n",
    "        for i in range(3):\n",
    "            to_avg = [sample_dict[f'{j}_{band_}{i}_median'] for j in range(4)]\n",
    "            to_drop += [f'{j}_{band_}{i}_median' for j in range(4)]\n",
    "            accumulate_vals = tf.math.add_n(to_avg)\n",
    "            mean_vals = tf.math.divide(accumulate_vals, float(len(to_avg)))\n",
    "            sample_dict_out[f'{band_}{i}_median'] = mean_vals\n",
    "        for i in range(3):\n",
    "            to_avg = [sample_dict[f'{j}_{band_}{i}_diff'] for j in range(4)]\n",
    "            to_drop += [f'{j}_{band_}{i}_diff' for j in range(4)]\n",
    "            accumulate_vals = tf.math.add_n(to_avg)\n",
    "            mean_vals = tf.math.divide(accumulate_vals, float(len(to_avg)))\n",
    "            sample_dict_out[f'{band_}{i}_diff'] = mean_vals\n",
    "            \n",
    "    for band_ in ['SR_TH']:\n",
    "        to_avg = [sample_dict[f'{j}_{band_}_median'] for j in range(4)]\n",
    "        to_drop += [f'{j}_{band_}_median' for j in range(4)]\n",
    "        accumulate_vals = tf.math.add_n(to_avg)\n",
    "        mean_vals = tf.math.divide(accumulate_vals, float(len(to_avg)))\n",
    "        sample_dict_out[f'{band_}_median'] = mean_vals\n",
    "        \n",
    "        to_avg = [sample_dict[f'{j}_{band_}_diff'] for j in range(4)]\n",
    "        to_drop += [f'{j}_{band_}_diff' for j in range(4)]\n",
    "        accumulate_vals = tf.math.add_n(to_avg)\n",
    "        mean_vals = tf.math.divide(accumulate_vals, float(len(to_avg)))\n",
    "        sample_dict_out[f'{band_}_diff'] = mean_vals\n",
    "    for key in ALL_FEATURES:\n",
    "        if key in to_drop:\n",
    "            continue\n",
    "        sample_dict_out[key] = sample_dict[key]\n",
    "    return sample_dict_out\n",
    "\n",
    "def check_other_class(sample_dict):\n",
    "    '''\n",
    "    This checks that the class other is not more than a certain threshold\n",
    "    This is to avoid having an over representation of non-ag pixels\n",
    "    '''\n",
    "    other_threshold = 0.66*KERNEL_SIZE*KERNEL_SIZE\n",
    "    sum_other = tf.math.reduce_sum(sample_dict['other'])\n",
    "    if tf.math.greater(sum_other, other_threshold):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "        \n",
    "\n",
    "\n",
    "class tfr_fhandle:\n",
    "    def __init__(self, fname):\n",
    "        filename = fname+\".tfrecords\"\n",
    "        self.tfrwriter = tf.io.TFRecordWriter(filename)\n",
    "    def close(self):\n",
    "        self.tfrwriter.close()\n",
    "    def write(self, datastream):\n",
    "        self.tfrwriter.write(datastream)\n",
    "        \n",
    "        \n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))): # if value ist tensor\n",
    "        value = value.numpy() # get value of tensor\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "  \"\"\"Returns a floast_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def serialize_array(array):\n",
    "  array = tf.io.serialize_tensor(array)\n",
    "  return array\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def parse_single_sample(feature):\n",
    "    data = {}\n",
    "    for feature_name in SAVED_BANDS:\n",
    "        data[feature_name] = _bytes_feature(serialize_array(np.array(feature[feature_name], dtype = 'float32')))\n",
    "    for resp in RESPONSE:\n",
    "        data[resp] = _bytes_feature(serialize_array(np.array(feature[resp], dtype = 'float32')))\n",
    "    out = tf.train.Example(features=tf.train.Features(feature=data))\n",
    "    return out\n",
    "\n",
    "\n",
    "def write_examples_to_tfr(all_features_list, tfr_writer):\n",
    "    count_ = 0\n",
    "    for thisfeature in all_features_list:\n",
    "        if not check_other_class(thisfeature):\n",
    "            continue\n",
    "        out = parse_single_sample(thisfeature)\n",
    "        tfr_writer.write(out.SerializeToString()) ##Uncomment this if needed to write to the one aggregated tfrecord file\n",
    "        count_ += 1\n",
    "    print(f\"Wrote {count_} elements to TFRecord\")\n",
    "    return count_\n",
    "\n",
    "\n",
    "def get_dataset(fname):\n",
    "    \"\"\"Function to read, parse and format to tuple a set of input tfrecord files.\n",
    "    Get all the files matching the pattern, parse and convert to tuple.\n",
    "    Args:\n",
    "    pattern: A file pattern to match in a Cloud Storage bucket.\n",
    "    Returns:\n",
    "    A tf.data.Dataset\n",
    "    \"\"\"\n",
    "    print(fname)\n",
    "    dataset = tf.data.TFRecordDataset(fname, compression_type='GZIP')\n",
    "    dataset = dataset.map(parse_tfrecord)\n",
    "    dataset = dataset.map(sample_to_dict)\n",
    "    dataset = dataset.map(normalize_input)\n",
    "    dataset = dataset.map(save_average_input)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# Use the helpers to read in the training dataset.  Print the first record to check.\n",
    "\n",
    "# In[36]:\n",
    "YEARS = []\n",
    "\n",
    "MINYEAR = 2003\n",
    "MAXYEAR = 2022\n",
    "\n",
    "FOLDERS = {}\n",
    "\n",
    "for year in range(MINYEAR,MAXYEAR):\n",
    "    if year not in [2012,2016,2017]:\n",
    "        YEARS.append(year)\n",
    "    FOLDERS[year]=BASEFOLDER\n",
    "        \n",
    "        \n",
    "NSamples = {BASEFOLDER:{'Training':{},'Evaluation':{}}}\n",
    "\n",
    "\n",
    "def save_training_dataset():\n",
    "    \"\"\"Get the preprocessed training dataset\n",
    "    Returns: \n",
    "    A tf.data.Dataset of training data.\n",
    "    \"\"\"\n",
    "    \n",
    "    for year in YEARS:\n",
    "        FOLDER = FOLDERS[year]\n",
    "        fname = f'{BASEFOLDER}/Samples_{year}_{TRAINING_BASE}.tfrecord.gz'\n",
    "        dataset = get_dataset(fname)\n",
    "        dat_fname = f'{FOLDER}/Proc_Samples_{year}_{TRAINING_BASE}'\n",
    "        tfr_writer = tfr_fhandle(dat_fname)\n",
    "        ncount = write_examples_to_tfr(dataset, tfr_writer)\n",
    "        NSamples[FOLDER]['Training'][year]=ncount\n",
    "        if os.path.exists(f'{FOLDER}/Samples_TFCC_{year}_{TRAINING_BASE}.tfrecord.gz'):\n",
    "            fname = f'{FOLDER}/Samples_TFCC_{year}_{TRAINING_BASE}.tfrecord.gz'\n",
    "            dataset = get_dataset(fname)\n",
    "            ncount = write_examples_to_tfr(dataset, tfr_writer)\n",
    "            NSamples[FOLDER]['Training'][year] += ncount\n",
    "        tfr_writer.close()\n",
    "        \n",
    "    return \n",
    "\n",
    "def save_eval_dataset():\n",
    "    \"\"\"Get the preprocessed training dataset\n",
    "    Returns: \n",
    "    A tf.data.Dataset of training data.\n",
    "    \"\"\"\n",
    "    for year in YEARS:\n",
    "        FOLDER = FOLDERS[year]\n",
    "        fname = f'{BASEFOLDER}/Samples_{year}_{EVAL_BASE}.tfrecord.gz'\n",
    "        dataset = get_dataset(fname)\n",
    "        dat_fname = f'{FOLDER}/Proc_Samples_{year}_{EVAL_BASE}'\n",
    "        tfr_writer = tfr_fhandle(dat_fname)\n",
    "        ncount = write_examples_to_tfr(dataset, tfr_writer)\n",
    "        NSamples[FOLDER]['Evaluation'][year]=ncount\n",
    "        if os.path.exists(f'{FOLDER}/Samples_TFCC_{year}_{EVAL_BASE}.tfrecord.gz'):\n",
    "            fname = f'{FOLDER}/Samples_TFCC_{year}_{EVAL_BASE}.tfrecord.gz'\n",
    "            dataset = get_dataset(fname)\n",
    "            ncount = write_examples_to_tfr(dataset, tfr_writer)\n",
    "            NSamples[FOLDER]['Evaluation'][year] += ncount\n",
    "        \n",
    "        tfr_writer.close()\n",
    "    return \n",
    "\n",
    "save_training_dataset()\n",
    "save_eval_dataset()\n",
    "for fold_ in NSamples:\n",
    "    outputjson = f'{fold_}/NSamples.json'\n",
    "    import json\n",
    "    with open(outputjson,'w') as fh:\n",
    "        json.dump(NSamples[fold_], fh)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a315bada-2b66-4d1e-bc41-298bd952d675",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow 2.13.0",
   "language": "python",
   "name": "tensorflow-2.13.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
